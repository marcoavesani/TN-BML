{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:05:24.105000Z",
     "start_time": "2017-06-14T09:05:21.967000Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.special import binom\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import pandas as pd\n",
    "import mpnum as mp\n",
    "import sklearn\n",
    "import plotly.offline as ply\n",
    "from sklearn import svm\n",
    "from numba import autojit\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeeeeping!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Ausiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit\n",
    "def feature_map(x):\n",
    "    \"\"\"Local feature map\"\"\"\n",
    "    \n",
    "    x_arr = 0.5 * np.pi * np.array([x]*d)\n",
    "    s = np.arange(d)\n",
    "    return np.sqrt(binom([d-1]*d,s)) * np.power(np.cos(x_arr), d-1-s) * np.power(np.sin(x_arr), s)\n",
    "\n",
    "@autojit\n",
    "def Tdelta(l):\n",
    "    \"\"\"Create a tensor kronecker delta\"\"\"\n",
    "    return mp.MPArray.from_kron([np.array([1-l,l])])\n",
    "\n",
    "@autojit\n",
    "def evaluate(Tweight, x, y):\n",
    "    xy_mpa = mp.MPArray.from_kron([feature_map(x),feature_map(y)]).group_sites(2) # feature tensor\n",
    "    Tf = mp.dot(Tweight,xy_mpa,axes=([1,2],[0,1]))\n",
    "    W0 = mp.dot(Tf, Tdelta(0)).to_array()\n",
    "    W1 = mp.dot(Tf, Tdelta(1)).to_array()\n",
    "    Wdiff = W0 - W1\n",
    "    Wsum = W0 + W1\n",
    "    return Wdiff * Wsum / np.abs(Wdiff * Wsum)\n",
    "\n",
    "def plot_tn_decision_function(Tweight, ax=None):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 100)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 100)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    P = np.zeros_like(X)\n",
    "    for i, xi in enumerate(x):\n",
    "        for j, yj in enumerate(y):\n",
    "            P[i, j] =evaluate(Tweight,xi,yj)\n",
    "    # plot the margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "\n",
    "def plot_svc_decision_function(clf, ax=None):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 100)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 100)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    P = np.zeros_like(X)\n",
    "    for i, xi in enumerate(x):\n",
    "        for j, yj in enumerate(y):\n",
    "            P[i, j] = clf.decision_function(np.c_[xi.ravel(), yj.ravel()])\n",
    "    # plot the margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sweeping algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit\n",
    "def update2sites(data, label, Tweight):    \n",
    "    TdeltaB = mp.MPArray.from_kron([np.array([0]*2), np.array([0]*d), np.array([0]*d)]).group_sites(3) #null tensor deltaB (single size)\n",
    "    for idx in range(len(data)):\n",
    "        # create the full feature map\n",
    "        xy_mpa = mp.MPArray.from_kron([feature_map(data[idx][0]),feature_map(data[idx][1])]).group_sites(2) # feature tensor\n",
    "        # tensot product between the weights and the feature map\n",
    "        Tf = mp.dot(Tweight,xy_mpa,axes=([1,2],[0,1])) # the last two physical legs are of Tweight are contracted with the feature tensor\n",
    "        Tcoef = (Tdelta(label[idx]) - Tf)\n",
    "        Ttemp = mp.MPArray.from_kron([Tcoef.to_array(), xy_mpa.to_array()]).group_sites(2)\n",
    "        TdeltaB = TdeltaB + Ttemp\n",
    "    \n",
    "    Tweight = Tweight + alpha * TdeltaB\n",
    "    return Tweight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T08:51:01.644000Z",
     "start_time": "2017-06-14T08:51:01.636000Z"
    }
   },
   "source": [
    "# Classify data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two overlapping  gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1=[0.3,0.3]\n",
    "cov1=[[0.001,0],[0,0.001]]\n",
    "mean2=[0.4,0.4]\n",
    "cov2=[[0.001,0],[0,0.001]]\n",
    "class0=np.random.multivariate_normal(mean1, cov1, 10000)\n",
    "class1=np.random.multivariate_normal(mean2, cov2, 10000)\n",
    "\n",
    "f1=plt.figure()\n",
    "plt.plot(class0.T[0],class0.T[1],\".\")\n",
    "plt.plot(class1.T[0],class1.T[1],\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata], class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata), np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # local dimension\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 100\n",
    "alpha = 5e-4 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 10000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='linear', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 10000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi circular uniform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 10000\n",
    "class0_radius = np.random.uniform(0, 0.5, max_data)\n",
    "class0_phase = np.random.uniform(0, 0.5*np.pi, max_data)\n",
    "class1_radius = np.random.uniform(0.5, 1, max_data)\n",
    "class1_phase = np.random.uniform(0, 0.5*np.pi, max_data)\n",
    "\n",
    "x0 = np.array([class0_radius*np.cos(class0_phase)])\n",
    "y0 = np.array([class0_radius*np.sin(class0_phase)])\n",
    "class0 = np.concatenate((x0.T, y0.T), axis=1)\n",
    "\n",
    "x1 = np.array([class1_radius*np.cos(class1_phase)])\n",
    "y1 = np.array([class1_radius*np.sin(class1_phase)])\n",
    "class1 = np.concatenate((x1.T, y1.T), axis=1)\n",
    "\n",
    "plt.plot(class0[:,0], class0[:,1], '.')\n",
    "plt.plot(class1[:,0], class1[:,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 200\n",
    "alpha = 1e-3 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='poly', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 10000\n",
    "class0_radius = np.random.uniform(0, 0.5, max_data)\n",
    "class0_phase = np.random.uniform(0, 2*np.pi, max_data)\n",
    "class1_radius = np.random.uniform(0.5, 1, max_data)\n",
    "class1_phase = np.random.uniform(0, 2*np.pi, max_data)\n",
    "\n",
    "x0 = np.array([class0_radius*np.cos(class0_phase)]) * 0.5 + 0.5\n",
    "y0 = np.array([class0_radius*np.sin(class0_phase)]) * 0.5 + 0.5\n",
    "class0 = np.concatenate((x0.T, y0.T), axis=1)\n",
    "\n",
    "x1 = np.array([class1_radius*np.cos(class1_phase)]) * 0.5 + 0.5\n",
    "y1 = np.array([class1_radius*np.sin(class1_phase)]) * 0.5 + 0.5\n",
    "class1 = np.concatenate((x1.T, y1.T), axis=1)\n",
    "\n",
    "plt.plot(class0[:,0], class0[:,1], '.')\n",
    "plt.plot(class1[:,0], class1[:,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 200\n",
    "alpha = 1e-3 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='rbf', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiral distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 10000\n",
    "max_angle = 3*np.pi\n",
    "theta = np.random.uniform(0, max_angle, max_data)\n",
    "\n",
    "class0_phase = np.random.uniform(0, np.pi, max_data)\n",
    "class1_phase = np.random.uniform(0, -np.pi, max_data)\n",
    "\n",
    "x0 = np.array([theta * np.cos(theta + class0_phase)]) * 0.5 / max_angle + 0.5\n",
    "y0 = np.array([theta * np.sin(theta + class0_phase)]) * 0.5 / max_angle + 0.5\n",
    "class0 = np.concatenate((x0.T, y0.T), axis=1)\n",
    "\n",
    "x1 = np.array([theta * np.cos(theta + class1_phase)]) * 0.5 / max_angle + 0.5\n",
    "y1 = np.array([theta * np.sin(theta + class1_phase)]) * 0.5 / max_angle + 0.5\n",
    "class1 = np.concatenate((x1.T, y1.T), axis=1)\n",
    "\n",
    "plt.plot(class0[:,0], class0[:,1], '.')\n",
    "plt.plot(class1[:,0], class1[:,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 70\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 100\n",
    "alpha = 1e-3 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='rbf', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
