{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T09:05:24.105000Z",
     "start_time": "2017-06-14T09:05:21.967000Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.offline as ply\n",
    "#ply.init_notebook_mode()\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.special import binom\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import plotly\n",
    "import pandas as pd\n",
    "import mpnum as mp\n",
    "import sklearn\n",
    "\n",
    "from sklearn import svm\n",
    "from numba import autojit\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "#%matplotlib notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeeeeping!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define Ausiliar functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit\n",
    "def feature_map(x):\n",
    "    \"\"\"Local feature map\"\"\"\n",
    "    \n",
    "    x_arr = 0.5 * np.pi * np.array([x]*d)\n",
    "    s = np.arange(d)\n",
    "    return np.sqrt(binom([d-1]*d,s)) * np.power(np.cos(x_arr), d-1-s) * np.power(np.sin(x_arr), s)\n",
    "\n",
    "@autojit\n",
    "def Tdelta(l):\n",
    "    \"\"\"Create a tensor kronecker delta\"\"\"\n",
    "    return mp.MPArray.from_kron([np.array([1-l,l])])\n",
    "\n",
    "@autojit\n",
    "def evaluate(Tweight, x, y):\n",
    "    xy_mpa = mp.MPArray.from_kron([feature_map(x),feature_map(y)]).group_sites(2) # feature tensor\n",
    "    Tf = mp.dot(Tweight,xy_mpa,axes=([1,2],[0,1]))\n",
    "    W0 = mp.dot(Tf, Tdelta(0)).to_array()\n",
    "    W1 = mp.dot(Tf, Tdelta(1)).to_array()\n",
    "    Wdiff = W0 - W1\n",
    "    Wsum = W0 + W1\n",
    "    return Wdiff * Wsum / np.abs(Wdiff * Wsum)\n",
    "\n",
    "def plot_tn_decision_function(Tweight, ax=None):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 100)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 100)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    P = np.zeros_like(X)\n",
    "    for i, xi in enumerate(x):\n",
    "        for j, yj in enumerate(y):\n",
    "            P[i, j] =evaluate(Tweight,xi,yj)\n",
    "    # plot the margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])\n",
    "\n",
    "def plot_svc_decision_function(clf, ax=None):\n",
    "    \"\"\"Plot the decision function for a 2D SVC\"\"\"\n",
    "    if ax is None:\n",
    "        ax = plt.gca()\n",
    "    x = np.linspace(plt.xlim()[0], plt.xlim()[1], 100)\n",
    "    y = np.linspace(plt.ylim()[0], plt.ylim()[1], 100)\n",
    "    Y, X = np.meshgrid(y, x)\n",
    "    P = np.zeros_like(X)\n",
    "    for i, xi in enumerate(x):\n",
    "        for j, yj in enumerate(y):\n",
    "            P[i, j] = clf.decision_function(np.c_[xi.ravel(), yj.ravel()])\n",
    "    # plot the margins\n",
    "    ax.contour(X, Y, P, colors='k',\n",
    "               levels=[-1, 0, 1], alpha=0.5,\n",
    "               linestyles=['--', '-', '--'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define sweeping algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit\n",
    "def update2sites(data, label, Tweight):    \n",
    "    TdeltaB = mp.MPArray.from_kron([np.array([0]*2), np.array([0]*d), np.array([0]*d)]).group_sites(3) #null tensor deltaB (single size)\n",
    "    for idx in range(len(data)):\n",
    "        # create the full feature map\n",
    "        xy_mpa = mp.MPArray.from_kron([feature_map(data[idx][0]),feature_map(data[idx][1])]).group_sites(2) # feature tensor\n",
    "        # tensot product between the weights and the feature map\n",
    "        Tf = mp.dot(Tweight,xy_mpa,axes=([1,2],[0,1])) # the last two physical legs are of Tweight are contracted with the feature tensor\n",
    "        Tcoef = (Tdelta(label[idx]) - Tf)\n",
    "        Ttemp = mp.MPArray.from_kron([Tcoef.to_array(), xy_mpa.to_array()]).group_sites(2)\n",
    "        TdeltaB = TdeltaB + Ttemp\n",
    "    \n",
    "    Tweight = Tweight + alpha * TdeltaB\n",
    "    return Tweight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-14T08:51:01.644000Z",
     "start_time": "2017-06-14T08:51:01.636000Z"
    }
   },
   "source": [
    "# Classify data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two overlapping  gaussians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean1=[0.3,0.3]\n",
    "cov1=[[0.001,0],[0,0.001]]\n",
    "mean2=[0.4,0.4]\n",
    "cov2=[[0.001,0],[0,0.001]]\n",
    "class0=np.random.multivariate_normal(mean1, cov1, 10000)\n",
    "class1=np.random.multivariate_normal(mean2, cov2, 10000)\n",
    "\n",
    "f1=plt.figure()\n",
    "plt.plot(class0.T[0],class0.T[1],\".\")\n",
    "plt.plot(class1.T[0],class1.T[1],\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata], class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata), np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2 # local dimension\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 100\n",
    "alpha = 5e-4 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 10000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='linear', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 10000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi circular uniform distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 10000\n",
    "class0_radius = np.random.uniform(0, 0.5, max_data)\n",
    "class0_phase = np.random.uniform(0, 0.5*np.pi, max_data)\n",
    "class1_radius = np.random.uniform(0.5, 1, max_data)\n",
    "class1_phase = np.random.uniform(0, 0.5*np.pi, max_data)\n",
    "\n",
    "x0 = np.array([class0_radius*np.cos(class0_phase)])\n",
    "y0 = np.array([class0_radius*np.sin(class0_phase)])\n",
    "class0 = np.concatenate((x0.T, y0.T), axis=1)\n",
    "\n",
    "x1 = np.array([class1_radius*np.cos(class1_phase)])\n",
    "y1 = np.array([class1_radius*np.sin(class1_phase)])\n",
    "class1 = np.concatenate((x1.T, y1.T), axis=1)\n",
    "\n",
    "plt.plot(class0[:,0], class0[:,1], '.')\n",
    "plt.plot(class1[:,0], class1[:,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 200\n",
    "alpha = 1e-3 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='poly', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Circular distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 10000\n",
    "class0_radius = np.random.uniform(0, 0.5, max_data)\n",
    "class0_phase = np.random.uniform(0, 2*np.pi, max_data)\n",
    "class1_radius = np.random.uniform(0.5, 1, max_data)\n",
    "class1_phase = np.random.uniform(0, 2*np.pi, max_data)\n",
    "\n",
    "x0 = np.array([class0_radius*np.cos(class0_phase)]) * 0.5 + 0.5\n",
    "y0 = np.array([class0_radius*np.sin(class0_phase)]) * 0.5 + 0.5\n",
    "class0 = np.concatenate((x0.T, y0.T), axis=1)\n",
    "\n",
    "x1 = np.array([class1_radius*np.cos(class1_phase)]) * 0.5 + 0.5\n",
    "y1 = np.array([class1_radius*np.sin(class1_phase)]) * 0.5 + 0.5\n",
    "class1 = np.concatenate((x1.T, y1.T), axis=1)\n",
    "\n",
    "plt.plot(class0[:,0], class0[:,1], '.')\n",
    "plt.plot(class1[:,0], class1[:,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 3\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 200\n",
    "alpha = 1e-3 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='rbf', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiral distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_data = 10000\n",
    "max_angle = 3*np.pi\n",
    "theta = np.random.uniform(0, max_angle, max_data)\n",
    "\n",
    "class0_phase = np.random.uniform(0, np.pi, max_data)\n",
    "class1_phase = np.random.uniform(0, -np.pi, max_data)\n",
    "\n",
    "x0 = np.array([theta * np.cos(theta + class0_phase)]) * 0.5 / max_angle + 0.5\n",
    "y0 = np.array([theta * np.sin(theta + class0_phase)]) * 0.5 / max_angle + 0.5\n",
    "class0 = np.concatenate((x0.T, y0.T), axis=1)\n",
    "\n",
    "x1 = np.array([theta * np.cos(theta + class1_phase)]) * 0.5 / max_angle + 0.5\n",
    "y1 = np.array([theta * np.sin(theta + class1_phase)]) * 0.5 / max_angle + 0.5\n",
    "class1 = np.concatenate((x1.T, y1.T), axis=1)\n",
    "\n",
    "plt.plot(class0[:,0], class0[:,1], '.')\n",
    "plt.plot(class1[:,0], class1[:,1], '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "numdata = 1000\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate and update a random tensor weight using gradient descent steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 70\n",
    "rng = np.random.RandomState(seed=143)\n",
    "Tweight = mp.random_mpa(sites=1, ldim=[[2,d,d]], bdim=1, randstate=rng, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numsteps = 100\n",
    "alpha = 1e-3 # control convergence\n",
    "\n",
    "for idx in range(numsteps):\n",
    "    Tweight = update2sites(train_data, label, Tweight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_tn_decision_function(Tweight, ax=None)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assumed you have, X (predictor) and Y (target) for training data set and x_test(predictor) of test_dataset\n",
    "# Create SVM classification object \n",
    "model = svm.SVC(kernel='rbf', C=4, gamma=1) \n",
    "# there is various option associated with it, like changing kernel, gamma and C value. Will discuss more # about it in next section.Train the model using the training sets and check score\n",
    "model.fit(train_data, label)\n",
    "model.score(train_data, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_to_plot = 1000\n",
    "plt.plot(class0[0:point_to_plot,0], class0[0:point_to_plot,1], '.')\n",
    "plt.plot(class1[0:point_to_plot,0], class1[0:point_to_plot,1], '.')\n",
    "plot_svc_decision_function(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Sweeeeeping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@autojit\n",
    "def feature_map(x):\n",
    "    \"\"\"Local feature map\"\"\"\n",
    "    \n",
    "    x_arr = 0.5 * np.pi * np.array([x]*d)\n",
    "    s = np.arange(d)\n",
    "    return np.sqrt(binom([d-1]*d,s)) * np.power(np.cos(x_arr), d-1-s) * np.power(np.sin(x_arr), s)\n",
    "\n",
    "@autojit\n",
    "def Tdelta(l):\n",
    "    \"\"\"Create a tensor kronecker delta\"\"\"\n",
    "    return mp.MPArray.from_kron([np.array([1-l,l])])\n",
    "\n",
    "@autojit\n",
    "def evaluate(Tweight, x, y, z):\n",
    "    xyz_mpa = mp.MPArray.from_kron([feature_map(x),feature_map(y),feature_map(z)]).group_sites(3) # feature tensor\n",
    "    Tweight = Tweight.group_sites(3)\n",
    "    Tf = mp.dot(Tweight,xyz_mpa,axes=([1,2,3],[0,1,2]))\n",
    "    W0 = mp.dot(Tf, Tdelta(0)).to_array()\n",
    "    W1 = mp.dot(Tf, Tdelta(1)).to_array()\n",
    "    Wdiff = W0 - W1\n",
    "    Wsum = W0 + W1\n",
    "    return Wdiff * Wsum / np.abs(Wdiff * Wsum)\n",
    "\n",
    "def tn_decision_function(Tweight, class0, class1):\n",
    "    val0 = []\n",
    "    for v0 in class0:\n",
    "        val0.append(evaluate(Tweight, v0[0], v0[1], v0[2]))\n",
    "    \n",
    "    val1 = []\n",
    "    for v1 in class1:\n",
    "        val1.append(evaluate(Tweight, v1[0], v1[1], v1[2]))\n",
    "    \n",
    "    return val0, val1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "m = 1\n",
    "l = 1\n",
    "sites = 3\n",
    "\n",
    "rng = np.random.RandomState(seed=143)\n",
    "ldim = [[d]]*(sites-1)\n",
    "ldim.append([l,d])\n",
    "Tweight = mp.random_mpa(sites=sites, ldim=ldim[::-1], bdim=m, randstate=rng, normalized=True)\n",
    "print(Tweight.pdims)\n",
    "print(Tweight.bdims)\n",
    "print(Tweight.to_array())\n",
    "a,b=Tweight.split(0)\n",
    "print('---')\n",
    "print(a.pdims)\n",
    "print(a.to_array())\n",
    "print(b.pdims)\n",
    "print(b.to_array())\n",
    "r=mp.dot(a,b.group_sites(2),axes=(2,0))\n",
    "\n",
    "print(r.pdims)\n",
    "print(r.to_array())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#two gaussians 3D\n",
    "mean1=[0.3,0.3,0.3]\n",
    "cov1=[[0.001,0,0],[0,0.001,0],[0,0,0.001]]\n",
    "mean2=[0.4,0.4,0.4]\n",
    "cov2=[[0.001,0,0],[0,0.001,0],[0,0,0.001]]\n",
    "class0=np.random.multivariate_normal(mean1, cov1, 1)\n",
    "class1=np.random.multivariate_normal(mean2, cov2, 1)\n",
    "\n",
    "trace1 = Scatter3d(\n",
    "    x=class0.T[0],\n",
    "    y=class0.T[1],\n",
    "    z=class0.T[2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=3,\n",
    "        symbol = \"cross\",\n",
    "        line=dict(\n",
    "            width=0.5\n",
    "        )\n",
    "    )\n",
    ")\n",
    "trace2 = Scatter3d(\n",
    "    x=class1.T[0],\n",
    "    y=class1.T[1],\n",
    "    z=class1.T[2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        #color='rgb(127, 127, 127)',\n",
    "        size=3,\n",
    "        symbol='circle',\n",
    "        line=dict(\n",
    "            width=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data_plot = [trace1, trace2]\n",
    "layout = Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = Figure(data=data_plot, layout=layout)\n",
    "ply.plot(fig, filename='simple-3d-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sites(mpa, site_label):\n",
    "    \"\"\"Split physical legs of the site site_label so to have one leg per site\"\"\"\n",
    "    \n",
    "    max_num_site = len(t1)\n",
    "    if site_label > max_num_site - 1:\n",
    "        print(\"Site does not exist\")\n",
    "        return\n",
    "    if site_label < 0:\n",
    "        print(\"site must be non negative\")\n",
    "        return\n",
    "    \n",
    "    if site_label > 0:\n",
    "        mpa_left, mpa_center = mpa.split(site_label - 1)\n",
    "    else:\n",
    "        mpa_center = mpa\n",
    "        mpa_left = []\n",
    "        \n",
    "    if site_label < max_num_site - 1:\n",
    "        mpa_center, mpa_right = mpa_center.split(0)\n",
    "    else:\n",
    "        mpa_right = []\n",
    "    \n",
    "    mpa_center_nlegs = mpa_center.plegs[0]\n",
    "    mpa_center = mpa_center.split_sites(mpa_center.plegs[0])\n",
    "    mpa_list = [mpa_left, mpa_center, mpa_right]\n",
    "    mpa_list = [x for x in mpa_list if x]        # get rid of empty list\n",
    "    mpa_splitted = mp.outer(mpa_list)\n",
    "    \n",
    "    if site_label < max_num_site - 1:\n",
    "        mpa_splitted = mpa_splitted.pleg2bleg(site_label - 1 + mpa_center_nlegs)\n",
    "    if site_label > 0:\n",
    "        mpa_splitted = mpa_splitted.pleg2bleg(site_label - 1)\n",
    "\n",
    "    return mp.prune(mpa_splitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=143)\n",
    "t1=mp.random_mpa(sites=2, ldim=[[3,4],[4,2]], bdim=2, randstate=rng, normalized=True)\n",
    "site_to_split=1\n",
    "print(t1.pdims)\n",
    "mpa = split_sites(t1,site_to_split)\n",
    "print(mpa.pdims)\n",
    "print(mpa.reverse().pdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two gaussians 4D\n",
    "mean1=[0.3,0.3,0.3,0.3]\n",
    "cov1=[[0.001,0,0,0],[0,0.001,0,0],[0,0,0.001,0],[0,0,0,0.001]]\n",
    "mean2=[0.4,0.4,0.4,0.4]\n",
    "cov2=[[0.001,0,0,0],[0,0.001,0,0],[0,0,0.001,0],[0,0,0,0.001]]\n",
    "class0=np.random.multivariate_normal(mean1, cov1, 100)\n",
    "class1=np.random.multivariate_normal(mean2, cov2, 100)\n",
    "\n",
    "@autojit\n",
    "def Tdelta(l):\n",
    "    \"\"\"Create a tensor kronecker delta\"\"\"\n",
    "    return mp.MPArray.from_kron([np.array([1-l,l,0])])\n",
    "\n",
    "d = 4\n",
    "m = 2\n",
    "l = 3\n",
    "sites = 3\n",
    "alpha = 0.1\n",
    "\n",
    "rng = np.random.RandomState(seed=143)\n",
    "ldim = [[d]]*(sites-1)\n",
    "ldim.append([l,d])\n",
    "TW = mp.random_mpa(sites=sites, ldim=ldim[::-1], bdim=m, randstate=rng, normalized=True)\n",
    "\n",
    "numdata = 10\n",
    "train_data = np.concatenate([class0[0:numdata],class1[0:numdata]])\n",
    "label = np.concatenate([np.array([0]*numdata),np.array([1]*numdata)])\n",
    "\n",
    "#bond 0  \n",
    "bond = 0\n",
    "B, TW_right = TW.split(1)\n",
    "B = B.group_sites(2)\n",
    "TdeltaB = mp.MPArray.from_kron([np.array([0]*l), np.array([0]*d), np.array([0]*d), np.array([0]*m)]).group_sites(4) #null tensor deltaB (single size\n",
    "for idx in range(2):\n",
    "    TPhi = mp.MPArray.from_kron([feature_map(train_data[idx][0]), feature_map(train_data[idx][1])]) # feature tensor\n",
    "    TPhi_right = mp.MPArray.from_kron([feature_map(train_data[idx][n_site]) for n_site in range(2, sites)])\n",
    "\n",
    "    TWPhi_right = mp.prune(mp.dot(TW_right, TPhi_right, axes=(-1,0)))\n",
    "    TPhiTilde = mp.outer([TPhi, TWPhi_right]).group_sites(3)\n",
    "    \n",
    "    Tf = mp.prune(mp.dot(B, TPhiTilde, axes=([1,2,3],[0,1,2])))\n",
    "    \n",
    "    Tcoef = (Tdelta(label[idx]) - Tf)\n",
    "    Ttemp = mp.outer([Tcoef, TPhiTilde]).group_sites(2)\n",
    "    TdeltaB = TdeltaB + Ttemp\n",
    "\n",
    "B = B + alpha * TdeltaB\n",
    "\n",
    "B = B.transpose([1,0,2,3])\n",
    "B = B.split_sites(4)\n",
    "Bl, Br = B.split(0)\n",
    "Br = Br.group_sites(3)\n",
    "Bsvd = mp.outer([Bl,Br]).pleg2bleg(0)\n",
    "Bsvd.compress(method='svd', bdim=m)\n",
    "\n",
    "#bond 1\n",
    "bond = 1\n",
    "TW_left, Bl = Bsvd.split(0)\n",
    "B = mp.prune(mp.outer([Bl,TW_right]).pleg2bleg(0)).group_sites(2)\n",
    "\n",
    "TdeltaB = mp.MPArray.from_kron([np.array([0]*m), np.array([0]*l), np.array([0]*d), np.array([0]*d)]).group_sites(4) #null tensor deltaB (single size\n",
    "for idx in range(2):\n",
    "    TPhi = mp.MPArray.from_kron([feature_map(train_data[idx][1]), feature_map(train_data[idx][2])]) # feature tensor\n",
    "    TPhi_left = mp.MPArray.from_kron([feature_map(train_data[idx][0])])\n",
    "\n",
    "    TWPhi_left = mp.prune(mp.dot(TW_left, TPhi_left, axes=(0,0)))\n",
    "    TPhiTilde = mp.outer([TWPhi_left, TPhi]).group_sites(3)\n",
    "    \n",
    "    Tf = mp.prune(mp.dot(B, TPhiTilde, axes=([0,2,3],[0,1,2])))\n",
    "    \n",
    "    Tcoef = (Tdelta(label[idx]) - Tf)\n",
    "    Ttemp = mp.outer([Tcoef, TPhiTilde]).group_sites(2).transpose([1,0,2,3])\n",
    "    TdeltaB = TdeltaB + Ttemp\n",
    "\n",
    "B = B + alpha * TdeltaB\n",
    "B = B.transpose([0,2,1,3])\n",
    "B = B.split_sites(4)\n",
    "Bl, Br = B.split(1)\n",
    "Bl = Bl.group_sites(2)\n",
    "Br = Br.group_sites(2)\n",
    "Bsvd = mp.outer([Bl,Br]).pleg2bleg(0)\n",
    "Bsvd.compress(method='svd', bdim=m)\n",
    "\n",
    "TW = mp.outer([TW_left,Bsvd]).pleg2bleg(0)\n",
    "TW = TW.reverse()\n",
    "\n",
    "# update Weight with reversed algorithm\n",
    "#bond 0  \n",
    "bond = 0\n",
    "B, TW_right = TW.split(1)\n",
    "B = B.group_sites(2)\n",
    "TdeltaB = mp.MPArray.from_kron([np.array([0]*l), np.array([0]*d), np.array([0]*d), np.array([0]*m)]).group_sites(4) #null tensor deltaB (single size\n",
    "for idx in range(2):\n",
    "    TPhi = mp.MPArray.from_kron([feature_map(train_data[idx][2]), feature_map(train_data[idx][1])]) # feature tensor\n",
    "    TPhi_right = mp.MPArray.from_kron([feature_map(train_data[idx][n_site]) for n_site in range(2, sites)])\n",
    "\n",
    "    TWPhi_right = mp.prune(mp.dot(TW_right, TPhi_right, axes=(-1,0)))\n",
    "    TPhiTilde = mp.outer([TPhi, TWPhi_right]).group_sites(3)\n",
    "    \n",
    "    Tf = mp.prune(mp.dot(B, TPhiTilde, axes=([1,2,3],[0,1,2])))\n",
    "    \n",
    "    Tcoef = (Tdelta(label[idx]) - Tf)\n",
    "    Ttemp = mp.outer([Tcoef, TPhiTilde]).group_sites(2)\n",
    "    TdeltaB = TdeltaB + Ttemp\n",
    "\n",
    "B = B + alpha * TdeltaB\n",
    "B = B.transpose([1,0,2,3])\n",
    "B = B.split_sites(4)\n",
    "Bl, Br = B.split(0)\n",
    "Br = Br.group_sites(3)\n",
    "Bsvd = mp.outer([Bl,Br]).pleg2bleg(0)\n",
    "Bsvd.compress(method='svd', bdim=m)\n",
    "\n",
    "#bond 1\n",
    "bond = 1\n",
    "TW_left, Bl = Bsvd.split(0)\n",
    "B = mp.prune(mp.outer([Bl,TW_right]).pleg2bleg(0)).group_sites(2)\n",
    "\n",
    "TdeltaB = mp.MPArray.from_kron([np.array([0]*m), np.array([0]*l), np.array([0]*d), np.array([0]*d)]).group_sites(4) #null tensor deltaB (single size\n",
    "for idx in range(2):\n",
    "    TPhi = mp.MPArray.from_kron([feature_map(train_data[idx][1]), feature_map(train_data[idx][0])]) # feature tensor\n",
    "    TPhi_left = mp.MPArray.from_kron([feature_map(train_data[idx][0])])\n",
    "\n",
    "    TWPhi_left = mp.prune(mp.dot(TW_left, TPhi_left, axes=(0,0)))\n",
    "    TPhiTilde = mp.outer([TWPhi_left, TPhi]).group_sites(3)\n",
    "    \n",
    "    Tf = mp.prune(mp.dot(B, TPhiTilde, axes=([0,2,3],[0,1,2])))\n",
    "    \n",
    "    Tcoef = (Tdelta(label[idx]) - Tf)\n",
    "    Ttemp = mp.outer([Tcoef, TPhiTilde]).group_sites(2).transpose([1,0,2,3])\n",
    "    TdeltaB = TdeltaB + Ttemp\n",
    "\n",
    "B = B + alpha * TdeltaB\n",
    "B = B.transpose([0,2,1,3])\n",
    "B = B.split_sites(4)\n",
    "Bl, Br = B.split(1)\n",
    "Bl = Bl.group_sites(2)\n",
    "Br = Br.group_sites(2)\n",
    "Bsvd = mp.outer([Bl,Br]).pleg2bleg(0)\n",
    "Bsvd.compress(method='svd', bdim=m)\n",
    "\n",
    "TW = mp.outer([TW_left,Bsvd]).pleg2bleg(0)\n",
    "TW = TW.reverse()\n",
    "\n",
    "#mpa2 = mp.MPArray.from_kron([np.array([1,0,0,0]),np.array([1,0,0,0]),np.array([1,0,0,0])])\n",
    "#a=mp.dot(TW, mpa2)\n",
    "#print(TdeltaB.pdims)\n",
    "print(TW.pdims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#two gaussians 3D\n",
    "d = 4\n",
    "m = 2\n",
    "l = 3\n",
    "sites = 3\n",
    "alpha = 0.1\n",
    "\n",
    "rng = np.random.RandomState(seed=143)\n",
    "ldim = [[d]]*(sites-1)\n",
    "ldim.append([l,d])\n",
    "#TW = mp.random_mpa(sites=sites, ldim=ldim[::-1], bdim=m, randstate=rng, normalized=True)\n",
    "\n",
    "mean1=[0.3,0.3,0.3]\n",
    "cov1=[[0.001,0,0],[0,0.001,0],[0,0,0.001]]\n",
    "mean2=[0.4,0.4,0.4]\n",
    "cov2=[[0.001,0,0],[0,0.001,0],[0,0,0.001]]\n",
    "class0=np.random.multivariate_normal(mean1, cov1, 1000)\n",
    "class1=np.random.multivariate_normal(mean2, cov2, 1000)\n",
    "\n",
    "cl0, cl1 = tn_decision_function(TW, class0, class1)\n",
    "\n",
    "trace1 = Scatter3d(\n",
    "    x=class0.T[0],\n",
    "    y=class0.T[1],\n",
    "    z=class0.T[2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        size=10,\n",
    "        symbol = \"circle\",\n",
    "        color = (np.array(cl0) + 1)*0.5,\n",
    "        colorscale=[[0, 'rgb(0,0,255)'], [1, 'rgb(255,0,0)']],\n",
    "        line=dict(\n",
    "            width=0.5\n",
    "        )\n",
    "    )\n",
    ")\n",
    "trace2 = Scatter3d(\n",
    "    x=class1.T[0],\n",
    "    y=class1.T[1],\n",
    "    z=class1.T[2],\n",
    "    mode='markers',\n",
    "    marker=dict(\n",
    "        #color='rgb(127, 127, 127)',\n",
    "        size=3,\n",
    "        symbol='circle',\n",
    "        line=dict(\n",
    "            width=1\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data_plot = [trace1]#, trace2]\n",
    "layout = Layout(\n",
    "    margin=dict(\n",
    "        l=0,\n",
    "        r=0,\n",
    "        b=0,\n",
    "        t=0\n",
    "    )\n",
    ")\n",
    "fig = Figure(data=data_plot, layout=layout)\n",
    "ply.iplot(fig, filename='simple-3d-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
